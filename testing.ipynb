{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0')"
  },
  "interpreter": {
   "hash": "343b6ac7eff0d382f058e14c2ddeb6cb57577d740f11beca8e43569b1defe6e1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Testing notebook playground for extracting data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as msc\n",
    "import json\n",
    "import tweepy\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import pprint\n",
    "import datetime\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file into JSON object\n",
    "configFile = open('config.json')\n",
    "config = json.load(configFile)\n",
    "\n",
    "# make connection to the GCloud database\n",
    "db_config = config['database']\n",
    "connection = msc.connect(\n",
    "    host=db_config['host'], \n",
    "    port=db_config['port'],\n",
    "    user=db_config['user'],\n",
    "    password=db_config['password'],\n",
    "    database=db_config['database']\n",
    ")\n",
    "\n",
    "# authorize Twitter app with Tweepy OAuthHandler\n",
    "twit_config = config['twitter']\n",
    "auth = tweepy.OAuthHandler(twit_config['api_key'], twit_config['api_key_secret'])\n",
    "auth.set_access_token(twit_config['access_token'], twit_config['access_token_secret'])\n",
    "twitapi = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Tweets from Malaysian MOH about Malaysian COVID-19 case data\n",
    "# write to pandas database\n",
    "tweet_collection = twitapi.search(\"KKMPutrajaya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user id of @KKMPutrajaya\n",
    "url = \"https://api.twitter.com\"\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(twit_config['bearer_token'])}\n",
    "response = requests.request(\"GET\", url + \"/2/users/by/username/KKMPutrajaya\", headers=headers)\n",
    "user_id = response.json()['data']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pandas data set\n",
    "tweets = []\n",
    "next_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get posts from Malaysian MOH (@KKMPutrajaya)\n",
    "search_url = (url + \"/2/users/{}/tweets\".format(user_id))\n",
    "response = requests.request(\"GET\", search_url, headers=headers)\n",
    "data = response.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch tweet data\n",
    "# this fetches thousands of MOH's tweets, which are factored into the quota for my \n",
    "# Twitter account, so beware!\n",
    "def fetch_data():\n",
    "\n",
    "    # get posts from Malaysian MOH (@KKMPutrajaya)\n",
    "    search_url = (url + \"/2/users/{}/tweets\".format(user_id))\n",
    "    response = requests.request(\"GET\", search_url, headers=headers)\n",
    "    data = response.json()['data']\n",
    "\n",
    "    # cycle and add to data\n",
    "    for tweet in data:\n",
    "        if \"Status Terkini #COVID19\" in tweet['text']:\n",
    "            tweets.append(tweet)\n",
    "    # get next pagination token\n",
    "    next_token = response.json()['meta'].get('next_token')\n",
    "    next_tokens.append(next_token)\n",
    "    # while next token is not None (ie there is still a next page)\n",
    "    while next_token is not None:\n",
    "        # get next page\n",
    "        search_url = (url + \"/2/users/{}/tweets?pagination_token={}\".format(user_id, next_token))\n",
    "        response = requests.request(\"GET\", search_url, headers=headers)\n",
    "        data = response.json()['data']\n",
    "        next_token = response.json()['meta'].get('next_token')\n",
    "        # cycle through the next page\n",
    "        for tweet in data:\n",
    "            if \"Status Terkini #COVID19\" in tweet['text']:\n",
    "                tweets.append(tweet)\n",
    "                print(tweet)\n",
    "                next_tokens.append(next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsdf = pd.DataFrame(tweets)\n",
    "tweetsdf = tweetsdf[0:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_tokensdf = pd.DataFrame(next_tokens)\n",
    "next_tokensdf = next_tokensdf[0:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8efe339a56b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweetsdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "tweetsdf['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsdf['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsdf['text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = (url + \"/2/users/{}/tweets?pagination_token={}\".format(user_id, \"7140dibdnow9c7btw3w3xuo59eonz5ff1wirbd9w1h7ao\"))\n",
    "response = requests.request(\"GET\", search_url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cycle through pages automatically\n",
    "print(next_token)\n",
    "def goForward():\n",
    "    global next_token\n",
    "    if next_token is None:\n",
    "        raise Exception(\"no next page\")\n",
    "    else:\n",
    "        search_url = (url + \"/2/users/{}/tweets?end_time={}&pagination_token={}\".format(user_id, \"2021-03-11T12:00:00Z\", next_token))\n",
    "        response = requests.request(\"GET\", search_url, headers=headers)\n",
    "        next_token = response.json()['meta'].get('next_token')\n",
    "        print(response.json()['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tweet = tweetsdf.iloc[0, :]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert python date to DD-MMM-YYYY, where \"MMM\" is the month in malay\n",
    "month_dict = [\n",
    "    'januari',\n",
    "    'februari',\n",
    "    'mac',\n",
    "    'april',\n",
    "    'mei',\n",
    "    'jun',\n",
    "    'julai',\n",
    "    'ogos',\n",
    "    'september',\n",
    "    'oktober',\n",
    "    'november',\n",
    "    'disember'\n",
    "]\n",
    "\n",
    "# month is in Malay (like the above)\n",
    "def parseDate(day, month, year):\n",
    "    return datetime.date(int(year), int(list(map(lambda m: m.title(), month_dict)).index(month))+1, int(day))\n",
    "\n",
    "# def convertDate(date):\n",
    "#     return date.strftime(\"%d-{}-%Y\".format(month_dict[int(date.strftime(\"%m\"))-1]).title())\n",
    "\n",
    "def convertDate(date):\n",
    "    return date.strftime(\"%#d-{}-%Y\".format(month_dict[int(date.strftime(\"%m\"))-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'6-april-2021'"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "convertDate(parseDate(\"6\", \"April\", \"2021\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser for tweet content\n",
    "def parseTweetContent(tweet):\n",
    "    # print(tweet)\n",
    "    # get tweet content without \\n and \n",
    "    # explode it via spaces\n",
    "    exploded_tweet = [x for x in re.split('\\n| |=', tweet.replace('\\n\\n', '\\n')) if x]\n",
    "    # print(exploded_tweet)\n",
    "    \n",
    "    # get date as \"YYYY MMM DD\", where the month is in Malay\n",
    "    date = parseDate(exploded_tweet[3], exploded_tweet[4], exploded_tweet[5])\n",
    "    # print(date)\n",
    "\n",
    "    try:\n",
    "\n",
    "        # get other data\n",
    "        # the numbers represent the indexes at which the relevant values are in\n",
    "        # the exploded tweet\n",
    "        data_dict = {\n",
    "            \"cured_cases\": 8,\n",
    "            \"total_cured_cases\": 12,\n",
    "            \"new_cases\": 16,\n",
    "            \"total_new_cases\": 23 if date <= datetime.date(2021, 6, 9) else 21,\n",
    "            \"deaths\": 26 if date <= datetime.date(2021, 6, 9) else 24,\n",
    "            \"total_deaths\": 30 if date <= datetime.date(2021, 6, 9) else 28,\n",
    "            \"icu_cases\": 35 if date <= datetime.date(2021, 6, 9) else 33,\n",
    "            \"resp_cases\": 39 if date <= datetime.date(2021, 6, 9) else 37\n",
    "        }\n",
    "        \n",
    "        # parse data\n",
    "        result = {name: int(exploded_tweet[value].replace(',', '')) for name, value in data_dict.items()} \n",
    "\n",
    "        # add date\n",
    "        result['date'] = date.strftime('%d %m %Y')\n",
    "        # return result\n",
    "        return result\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "        print('cannot parse tweet at date {}'.format(date))\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-66c86dc6b173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# example tweet content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparseTweetContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweetsdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# example tweet content\n",
    "parseTweetContent(tweetsdf['text'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6476cca2495b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# store data into csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparsed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparseTweetContent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweetsdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# parsed_data += ({\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     \"cured_cases\": 1830,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     \"total_cured_cases\": 304492,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# store data into csv\n",
    "parsed_data = list(map(parseTweetContent, list(tweetsdf['text'])))\n",
    "# parsed_data += ({\n",
    "#     \"cured_cases\": 1830,\n",
    "#     \"total_cured_cases\": 304492, \n",
    "#     \"new_cases\": 1470,\n",
    "#     \"total_new_cases\": 322409, \n",
    "#     \"deaths\": 3,\n",
    "#     \"total_deaths\": 1206, \n",
    "#     \"icu_cases\": 162,\n",
    "#     \"resp_cases\": 70,\n",
    "#     \"date\": \"13 03 2021\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'parsed_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-64889528cdcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"covid_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parsed_data' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(parsed_data)\n",
    "df.to_csv(\"covid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataset\n",
    "dataset = []\n",
    "# initialize variable to text mapping\n",
    "vtt_map = {\n",
    "    'cured_cases': 'Kes sembuh',\n",
    "    'new_cases': 'Kes baharu',\n",
    "    'import_cases': 'Kes import',\n",
    "    'local_cases': 'Kes tempatan',\n",
    "    'active_cases': 'Kes aktif',\n",
    "    'resp_asst_cases': 'Kes yang memerlukan rawatan',\n",
    "    'death_cases': 'Kes kematian',\n",
    "    'number_of_clusters': 'Jumlah kluster',\n",
    "    'number_of_new_clusters': 'Jumlah kluster baharu',\n",
    "    'number_of_expired_clusters': 'Jumlah kluster yang telah tamat',\n",
    "    'number_of_active_clusters': 'Jumlah kluster aktif'\n",
    "}"
   ]
  },
  {
   "source": [
    "### Testing out web scraper for kpkesihatan.com instead to fetch data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['21-januari-2021',\n",
       " '21-februari-2021',\n",
       " '21-mac-2021',\n",
       " '21-april-2021',\n",
       " '21-mei-2021',\n",
       " '21-jun-2021',\n",
       " '21-julai-2021',\n",
       " '21-ogos-2021',\n",
       " '21-september-2021',\n",
       " '21-oktober-2021',\n",
       " '21-november-2021',\n",
       " '21-disember-2021']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "[convertDate(datetime.datetime(2021, i, 21)) for i in range(1, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do formatting on this later\n",
    "def makeURL(date):\n",
    "    return \"https://kpkesihatan.com/{}/kenyataan-akhbar-kpk-{}-situasi-semasa-jangkitan-penyakit-coronavirus-2019-covid-19-di-malaysia/\".format(\n",
    "        date.strftime(\"%#d/%#m/%Y\"), \n",
    "        convertDate(date)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://kpkesihatan.com/21/6/2021/kenyataan-akhbar-kpk-21-jun-2021-situasi-semasa-jangkitan-penyakit-coronavirus-2019-covid-19-di-malaysia/'"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "makeURL(datetime.datetime(2021, 6, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create soup specifically for the response content\n",
    "# soup_cases = BeautifulSoup(str(result[1]), 'html.parser')\n",
    "# Create variable to (Malay) text mapping\n",
    "vtt_map = {\n",
    "    'cured_cases': 'Kes sembuh',\n",
    "    'new_cases': 'Kes baharu',\n",
    "    'import_cases': 'Kes import',\n",
    "    'local_cases': 'Kes tempatan',\n",
    "    'active_cases': 'Kes aktif',\n",
    "    'resp_asst_cases': 'Kes yang memerlukan rawatan',\n",
    "    'death_cases': 'Kes kematian',\n",
    "    # 'number_of_clusters': 'Jumlah kluster',\n",
    "    # 'number_of_new_clusters': 'Jumlah kluster baharu',\n",
    "    # 'number_of_expired_clusters': 'Jumlah kluster yang telah tamat',\n",
    "    # 'number_of_active_clusters': 'Jumlah kluster aktif'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get data from website by date\n",
    "def get_data(date):\n",
    "    # make url to website for date\n",
    "    url = makeURL(date)\n",
    "    result = None\n",
    "    response = None\n",
    "    # print(url)\n",
    "\n",
    "    # get content of website\n",
    "    response = requests.get(url)\n",
    "    # print(response)\n",
    "\n",
    "    if (response.status_code == 200):\n",
    "        # filter for the case data\n",
    "        # create soup object\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # get all bulleted lists\n",
    "        result = soup.find_all('ul')\n",
    "        # print(result)\n",
    "        cases_content = str(result[1])\n",
    "        # print(cases_content)\n",
    "\n",
    "        # get soup for cases\n",
    "        soup_cases = BeautifulSoup(cases_content, 'html.parser')\n",
    "\n",
    "        # store the data into the result object\n",
    "        day_data = {}\n",
    "        for var in vtt_map:\n",
    "            # Get the string containing the key words\n",
    "            keyword_string = str(soup_cases.find(lambda tag: tag.name == \"li\" and vtt_map[var] in tag.text))\n",
    "            # Get the soup for the specific string\n",
    "            soup_var = BeautifulSoup(keyword_string, 'html.parser')\n",
    "            # use the custom soup to extract the case data, which is stored into the day_data object\n",
    "            content = soup_var.find(lambda tag: tag.name == \"strong\").contents[0]\n",
    "            # parse the content to only extract the integer value for the corresponding variable\n",
    "            for s in [\"\\xa0\", \"kes\", \"kluster\", \" \", \",\", \";\"]:\n",
    "                content = content.replace(s, \"\")\n",
    "            # convert value to int\n",
    "            day_data[var] = int(content)\n",
    "\n",
    "        # put date into data\n",
    "        day_data['date'] = date.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "        # return result when done\n",
    "        return day_data\n",
    "    else:\n",
    "        print(\"{} returned {} error\".format(url, response.status_code))\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'cured_cases': 6083,\n",
       " 'new_cases': 7105,\n",
       " 'import_cases': 2,\n",
       " 'local_cases': 7103,\n",
       " 'active_cases': 80474,\n",
       " 'resp_asst_cases': 872,\n",
       " 'death_cases': 71,\n",
       " 'date': '01/06/2021'}"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "get_data(datetime.date(2021, 6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'cured_cases': 2486,\n",
       " 'new_cases': 1828,\n",
       " 'import_cases': 7,\n",
       " 'local_cases': 1821,\n",
       " 'active_cases': 25542,\n",
       " 'resp_asst_cases': 198,\n",
       " 'death_cases': 5,\n",
       " 'date': '01/03/2021'}"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "get_data(datetime.date(2021, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unable to retrieve data for the date 01/01/2021\n",
      "Unable to retrieve data for the date 02/01/2021\n",
      "Unable to retrieve data for the date 03/01/2021\n",
      "Unable to retrieve data for the date 04/01/2021\n",
      "Unable to retrieve data for the date 05/01/2021\n",
      "Unable to retrieve data for the date 06/01/2021\n",
      "Unable to retrieve data for the date 07/01/2021\n",
      "Unable to retrieve data for the date 08/01/2021\n",
      "Unable to retrieve data for the date 09/01/2021\n",
      "Unable to retrieve data for the date 10/01/2021\n",
      "Unable to retrieve data for the date 11/01/2021\n",
      "Unable to retrieve data for the date 12/01/2021\n",
      "Unable to retrieve data for the date 13/01/2021\n",
      "Unable to retrieve data for the date 14/01/2021\n",
      "Unable to retrieve data for the date 15/01/2021\n",
      "Unable to retrieve data for the date 16/01/2021\n",
      "Unable to retrieve data for the date 17/01/2021\n",
      "Unable to retrieve data for the date 18/01/2021\n",
      "Unable to retrieve data for the date 19/01/2021\n",
      "Data retrieved for the date 20/01/2021\n",
      "Data retrieved for the date 21/01/2021\n",
      "Data retrieved for the date 22/01/2021\n",
      "Data retrieved for the date 23/01/2021\n",
      "Data retrieved for the date 24/01/2021\n",
      "Data retrieved for the date 25/01/2021\n",
      "Data retrieved for the date 26/01/2021\n",
      "Data retrieved for the date 27/01/2021\n",
      "Unable to retrieve data for the date 28/01/2021\n",
      "Data retrieved for the date 29/01/2021\n",
      "Data retrieved for the date 30/01/2021\n",
      "Data retrieved for the date 31/01/2021\n",
      "Data retrieved for the date 01/02/2021\n",
      "Data retrieved for the date 02/02/2021\n",
      "Data retrieved for the date 03/02/2021\n",
      "Data retrieved for the date 04/02/2021\n",
      "Data retrieved for the date 05/02/2021\n",
      "Data retrieved for the date 06/02/2021\n",
      "Data retrieved for the date 07/02/2021\n",
      "Data retrieved for the date 08/02/2021\n",
      "Data retrieved for the date 09/02/2021\n",
      "Data retrieved for the date 10/02/2021\n",
      "Data retrieved for the date 11/02/2021\n",
      "Data retrieved for the date 12/02/2021\n",
      "Data retrieved for the date 13/02/2021\n",
      "Data retrieved for the date 14/02/2021\n",
      "Data retrieved for the date 15/02/2021\n",
      "Unable to retrieve data for the date 16/02/2021\n",
      "Data retrieved for the date 17/02/2021\n",
      "Data retrieved for the date 18/02/2021\n",
      "Data retrieved for the date 19/02/2021\n",
      "Unable to retrieve data for the date 20/02/2021\n",
      "Data retrieved for the date 21/02/2021\n",
      "Data retrieved for the date 22/02/2021\n",
      "Data retrieved for the date 23/02/2021\n",
      "Data retrieved for the date 24/02/2021\n",
      "Data retrieved for the date 25/02/2021\n",
      "Data retrieved for the date 26/02/2021\n",
      "Data retrieved for the date 27/02/2021\n",
      "Data retrieved for the date 28/02/2021\n",
      "Data retrieved for the date 01/03/2021\n",
      "Data retrieved for the date 02/03/2021\n",
      "Data retrieved for the date 03/03/2021\n",
      "Data retrieved for the date 04/03/2021\n",
      "Data retrieved for the date 05/03/2021\n",
      "Data retrieved for the date 06/03/2021\n",
      "Data retrieved for the date 07/03/2021\n",
      "Data retrieved for the date 08/03/2021\n",
      "Data retrieved for the date 09/03/2021\n",
      "Data retrieved for the date 10/03/2021\n",
      "Data retrieved for the date 11/03/2021\n",
      "Data retrieved for the date 12/03/2021\n",
      "Data retrieved for the date 13/03/2021\n",
      "Data retrieved for the date 14/03/2021\n",
      "Data retrieved for the date 15/03/2021\n",
      "Data retrieved for the date 16/03/2021\n",
      "Data retrieved for the date 17/03/2021\n",
      "Data retrieved for the date 18/03/2021\n",
      "Data retrieved for the date 19/03/2021\n",
      "Data retrieved for the date 20/03/2021\n",
      "Data retrieved for the date 21/03/2021\n",
      "Data retrieved for the date 22/03/2021\n",
      "Data retrieved for the date 23/03/2021\n",
      "Unable to retrieve data for the date 24/03/2021\n",
      "Data retrieved for the date 25/03/2021\n",
      "Data retrieved for the date 26/03/2021\n",
      "Data retrieved for the date 27/03/2021\n",
      "Data retrieved for the date 28/03/2021\n",
      "Data retrieved for the date 29/03/2021\n",
      "Data retrieved for the date 30/03/2021\n",
      "Unable to retrieve data for the date 31/03/2021\n",
      "Data retrieved for the date 01/04/2021\n",
      "Data retrieved for the date 02/04/2021\n",
      "Data retrieved for the date 03/04/2021\n",
      "Data retrieved for the date 04/04/2021\n",
      "Data retrieved for the date 05/04/2021\n",
      "Data retrieved for the date 06/04/2021\n",
      "Data retrieved for the date 07/04/2021\n",
      "Data retrieved for the date 08/04/2021\n",
      "Data retrieved for the date 09/04/2021\n",
      "Data retrieved for the date 10/04/2021\n",
      "Unable to retrieve data for the date 11/04/2021\n",
      "Data retrieved for the date 12/04/2021\n",
      "Data retrieved for the date 13/04/2021\n",
      "Data retrieved for the date 14/04/2021\n",
      "Data retrieved for the date 15/04/2021\n",
      "Data retrieved for the date 16/04/2021\n",
      "Data retrieved for the date 17/04/2021\n",
      "Data retrieved for the date 18/04/2021\n",
      "Data retrieved for the date 19/04/2021\n",
      "Data retrieved for the date 20/04/2021\n",
      "Data retrieved for the date 21/04/2021\n",
      "Data retrieved for the date 22/04/2021\n",
      "Data retrieved for the date 23/04/2021\n",
      "Data retrieved for the date 24/04/2021\n",
      "Data retrieved for the date 25/04/2021\n",
      "Data retrieved for the date 26/04/2021\n",
      "Data retrieved for the date 27/04/2021\n",
      "Data retrieved for the date 28/04/2021\n",
      "Data retrieved for the date 29/04/2021\n",
      "Data retrieved for the date 30/04/2021\n",
      "Data retrieved for the date 01/05/2021\n",
      "Data retrieved for the date 02/05/2021\n",
      "Data retrieved for the date 03/05/2021\n",
      "Data retrieved for the date 04/05/2021\n",
      "Data retrieved for the date 05/05/2021\n",
      "Data retrieved for the date 06/05/2021\n",
      "Data retrieved for the date 07/05/2021\n",
      "Data retrieved for the date 08/05/2021\n",
      "Data retrieved for the date 09/05/2021\n",
      "Data retrieved for the date 10/05/2021\n",
      "Data retrieved for the date 11/05/2021\n",
      "Data retrieved for the date 12/05/2021\n",
      "Data retrieved for the date 13/05/2021\n",
      "Data retrieved for the date 14/05/2021\n",
      "Data retrieved for the date 15/05/2021\n",
      "Data retrieved for the date 16/05/2021\n",
      "Data retrieved for the date 17/05/2021\n",
      "Data retrieved for the date 18/05/2021\n",
      "Data retrieved for the date 19/05/2021\n",
      "Data retrieved for the date 20/05/2021\n",
      "Data retrieved for the date 21/05/2021\n",
      "Data retrieved for the date 22/05/2021\n",
      "Data retrieved for the date 23/05/2021\n",
      "Data retrieved for the date 24/05/2021\n",
      "Data retrieved for the date 25/05/2021\n",
      "Data retrieved for the date 26/05/2021\n",
      "Data retrieved for the date 27/05/2021\n",
      "Data retrieved for the date 28/05/2021\n",
      "Data retrieved for the date 29/05/2021\n",
      "Data retrieved for the date 30/05/2021\n",
      "Data retrieved for the date 31/05/2021\n",
      "Data retrieved for the date 01/06/2021\n",
      "Data retrieved for the date 02/06/2021\n",
      "Data retrieved for the date 03/06/2021\n",
      "Data retrieved for the date 04/06/2021\n",
      "Data retrieved for the date 05/06/2021\n",
      "Data retrieved for the date 06/06/2021\n",
      "Data retrieved for the date 07/06/2021\n",
      "Data retrieved for the date 08/06/2021\n",
      "Data retrieved for the date 09/06/2021\n",
      "Data retrieved for the date 10/06/2021\n",
      "Data retrieved for the date 11/06/2021\n",
      "Data retrieved for the date 12/06/2021\n",
      "Data retrieved for the date 13/06/2021\n",
      "Data retrieved for the date 14/06/2021\n",
      "Data retrieved for the date 15/06/2021\n",
      "Data retrieved for the date 16/06/2021\n",
      "Data retrieved for the date 17/06/2021\n",
      "Data retrieved for the date 18/06/2021\n",
      "Data retrieved for the date 19/06/2021\n",
      "Data retrieved for the date 20/06/2021\n",
      "Data retrieved for the date 21/06/2021\n",
      "Data retrieved for the date 22/06/2021\n",
      "Data retrieved for the date 23/06/2021\n"
     ]
    }
   ],
   "source": [
    "# insert data from march onwards into dataset\n",
    "dataset = []\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date.today()\n",
    "failed_dates = []\n",
    "\n",
    "for dt in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "    try:\n",
    "        dataset.append(get_data(dt))\n",
    "        print(\"Data retrieved for the date {}\".format(dt.strftime(\"%d/%m/%Y\")))\n",
    "    except:\n",
    "        print(\"Unable to retrieve data for the date {}\".format(dt.strftime(\"%d/%m/%Y\")))\n",
    "        failed_dates.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     cured_cases  new_cases  import_cases  local_cases  active_cases  \\\n",
       "0              2       4008             5         4003         41087   \n",
       "1              2       3170             8         3162             4   \n",
       "2           2554       3631             6         3625            42   \n",
       "3           4313       4275            11         4264            42   \n",
       "4           4427       3346             7         3339            41   \n",
       "..           ...        ...           ...          ...           ...   \n",
       "144         6918       5911             1         5910         64523   \n",
       "145         5941       5293             7         5286         63815   \n",
       "146         5439       4611             8         4603         62918   \n",
       "147         5557       4743             2         4741         62027   \n",
       "148         6372       5244             7         5237         60816   \n",
       "\n",
       "     resp_asst_cases  death_cases        date  \n",
       "0                246           11  20/01/2021  \n",
       "1                260           12  21/01/2021  \n",
       "2                251           18  22/01/2021  \n",
       "3                260            7  23/01/2021  \n",
       "4                265           11  24/01/2021  \n",
       "..               ...          ...         ...  \n",
       "144              886           72  19/06/2021  \n",
       "145              880           60  20/06/2021  \n",
       "146              880           69  21/06/2021  \n",
       "147              875           77  22/06/2021  \n",
       "148              879           83  23/06/2021  \n",
       "\n",
       "[149 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cured_cases</th>\n      <th>new_cases</th>\n      <th>import_cases</th>\n      <th>local_cases</th>\n      <th>active_cases</th>\n      <th>resp_asst_cases</th>\n      <th>death_cases</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>4008</td>\n      <td>5</td>\n      <td>4003</td>\n      <td>41087</td>\n      <td>246</td>\n      <td>11</td>\n      <td>20/01/2021</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3170</td>\n      <td>8</td>\n      <td>3162</td>\n      <td>4</td>\n      <td>260</td>\n      <td>12</td>\n      <td>21/01/2021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2554</td>\n      <td>3631</td>\n      <td>6</td>\n      <td>3625</td>\n      <td>42</td>\n      <td>251</td>\n      <td>18</td>\n      <td>22/01/2021</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4313</td>\n      <td>4275</td>\n      <td>11</td>\n      <td>4264</td>\n      <td>42</td>\n      <td>260</td>\n      <td>7</td>\n      <td>23/01/2021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4427</td>\n      <td>3346</td>\n      <td>7</td>\n      <td>3339</td>\n      <td>41</td>\n      <td>265</td>\n      <td>11</td>\n      <td>24/01/2021</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>6918</td>\n      <td>5911</td>\n      <td>1</td>\n      <td>5910</td>\n      <td>64523</td>\n      <td>886</td>\n      <td>72</td>\n      <td>19/06/2021</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>5941</td>\n      <td>5293</td>\n      <td>7</td>\n      <td>5286</td>\n      <td>63815</td>\n      <td>880</td>\n      <td>60</td>\n      <td>20/06/2021</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>5439</td>\n      <td>4611</td>\n      <td>8</td>\n      <td>4603</td>\n      <td>62918</td>\n      <td>880</td>\n      <td>69</td>\n      <td>21/06/2021</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>5557</td>\n      <td>4743</td>\n      <td>2</td>\n      <td>4741</td>\n      <td>62027</td>\n      <td>875</td>\n      <td>77</td>\n      <td>22/06/2021</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6372</td>\n      <td>5244</td>\n      <td>7</td>\n      <td>5237</td>\n      <td>60816</td>\n      <td>879</td>\n      <td>83</td>\n      <td>23/06/2021</td>\n    </tr>\n  </tbody>\n</table>\n<p>149 rows  8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# export data to csv\n",
    "df = pd.DataFrame(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"covid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}